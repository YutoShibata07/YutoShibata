<html><head>
  <script type="text/javascript" async="" src="https://www.googletagmanager.com/gtag/js?id=G-QPJZ0J6NDH&amp;cx=c&amp;_slc=1"></script><script async="" src="//www.google-analytics.com/analytics.js"></script><script>
      (function (i, s, o, g, r, a, m) {
          i['GoogleAnalyticsObject'] = r;
          i[r] = i[r] || function () {
              (i[r].q = i[r].q || []).push(arguments)
          }, i[r].l = 1 * new Date();
          a = s.createElement(o),
              m = s.getElementsByTagName(o)[0];
          a.async = 1;
          a.src = g;
          m.parentNode.insertBefore(a, m)
      })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-108114467-1', 'auto');
      ga('send', 'pageview');
  </script>
  <meta name="viewport" content="“width=800”">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <link href="https://fonts.googleapis.com/css?family=Titillium Web" rel="stylesheet">
  <meta charset="utf-8">
  <style type="text/css">
      /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
      a {
          color: #1772d0;
          text-decoration: none;
      }

      a:focus, a:hover {
          color: #f09228;
          text-decoration: none;
      }

      body, td, th {
          font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
          font-size: 16px;
          font-weight: 400
      }

      heading {
          font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
          font-size: 19px;
          font-weight: 1000
      }

      strong {
          font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
          font-size: 16px;
          font-weight: 800
      }

      strongred {
          font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
          color: 'red';
          font-size: 16px
      }

      sectionheading {
          font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
          font-size: 22px;
          font-weight: 600
      }
  </style>
  <title>Yuto Shibata</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <script async="" defer="" src="https://buttons.github.io/buttons.js"></script>
</head>
<body data-new-gr-c-s-check-loaded="14.1201.0" data-gr-ext-installed="" class="vsc-initialized">
<table width="1000" border="0" align="center" cellspacing="0" cellpadding="20">
  <tbody><tr>
      <td halign="center">
          <p align="center">
              <font size="6">Yuto Shibata 柴田優斗</font>
          </p>
      </td>
  </tr>
  <tr>
      <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr>
                  <td width="67%" valign="middle">
                      <p>I am a postdoctoral researcher at <a href="https://svl.stanford.edu/">Stanford Vision and Learning Lab (SVL)</a>
                          hosted by <a href="https://profiles.stanford.edu/fei-fei-li">Prof. Fei-Fei Li</a>
                          and <a href="https://stanford.edu/~eadeli/">Prof. Ehsan Adeli</a>.
                          I received my PhD from <a href="https://www.utexas.edu/">UT Austin</a>
                          advised by <a href="http://www.cs.utexas.edu/users/grauman/">Prof. Kristen Grauman</a>.
                          I am broadly interested at building machine learning models that perceive the world with
                          multi-modalities and interact with the world.
                          Currently, I work on multimodal perception and generation for 3D scenes and humans.
                      </p>
                      <p>Previously,  I spent five months working with <a href="https://www.robots.ox.ac.uk/~vedaldi/">Prof. Andrea Vedaldi</a>
                          and <a href="https://nneverova.github.io/">Dr. Natalia Neverova</a> at FAIR, London.
                          I was a visiting researcher at <a href="https://research.fb.com/category/facebook-ai-research/">FAIR</a>
                          working with <a href="http://www.cs.utexas.edu/users/grauman/">Prof. Kristen Grauman</a> for two years.
                          In my undergrad, I spent a wonderful year working with <a href="http://www.cs.sfu.ca/~mori">Prof.
                          Greg Mori</a> on sports video analysis and efficient deep learning, eight months working with
                          <a href="http://web.stanford.edu/~alahi">Prof. Alexandre Alahi</a> on social navigation in
                          crowds, and eight months working with <a href="http://msavva.github.io">Prof. Manolis
                              Savva</a> on relational graph reasoning for navigation.</p>
                      <p>My first name is pronounced as /tʃæn'æn/ with the g being silent.</p>
                      <p><b>Research opportunities:</b> I am happy to collaborate with motivated undergrad and master students at Stanford.
                      I am also happy to answer questions about my research. If you are interested, please send me an email.</p>
                      <p align="center"><a>
                      </a><a href="files/cv.pdf">CV</a> | <a href="mailto:changanvr@gmail.com">E-Mail</a> | <a href="https://scholar.google.com/citations?hl=en&amp;user=9Uxf0ikAAAAJ">Google Scholar</a> |
                          <a href="https://github.com/ChanganVR">Github</a> |
                          <a href="https://twitter.com/changan_vr"> Twitter</a> |
                          <a href="files/dissertation.pdf">Dissertation</a>
                      </p>
                  </td>
                  <td width="100%" valign="top">
                      <img src="/images/YutoShibata.png" width="95%">
                  </td>
              </tr>
          </tbody></table>

  
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr>
                  <td width="100%" valign="middle">
                      <heading>Publications</heading>
                  </td>
              </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr onmouseout="hoiswap_start()" onmouseover="hoiswap_stop()">
                  <td width="35%">
                      <div class="one">
                          <div class="two" id="hoiswap"><div class="vsc-controller"></div>
<!--                                <img src='images/action2sound.jpg' alt="sym" width="100%"-->
<!--                                                                    style="border-style: none">-->
                              <video width="100%" height="auto" autoplay="" loop="" muted="">
                                  <source src="images/hoiswap.mp4" type="video/mp4">
                              </video>
                          </div>
                      </div>
                      <script type="text/javascript">
                          function hoiswap_start() {
                              document.getElementById('hoiswap').style.opacity = "0.9";
                          }

                          function hoiswap_stop() {
                              document.getElementById('hoiswap').style.opacity = "1";
                          }

                          friendly_stop()
                      </script>
                  </td>
                  <td valign="top" width="65%">
                      <p><a href="">
                          <img src="images/new.png" alt="[NEW]" width="5%" style="border-style: none">
                          <heading>HOI-Swap: Swapping Objects in Videos with Hand-Object Interaction Awareness</heading>
                      </a><br>Zihui Xue, Mi Luo, <strong>Changan Chen<strong>, Kristen Grauman<br>
                          <em>arXiv 2024<br></em>
                          <a href="https://arxiv.org/abs/2406.07754">paper | </a>
                          <a href="https://vision.cs.utexas.edu/projects/HOI-Swap/">project</a>
                  </strong></strong></p></td>
              </tr>

          </tbody></table><table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr onmouseout="action2sound_start()" onmouseover="action2sound_stop()">
                  <td width="35%">
                      <div class="one">
                          <div class="two" id="action2sound" style="opacity: 0.9;"><img src="images/action2sound.jpg" alt="sym" width="100%" style="border-style: none"></div>
                      </div>
                      <script type="text/javascript">
                          function action2sound_start() {
                              document.getElementById('action2sound').style.opacity = "0.9";
                          }

                          function action2sound_stop() {
                              document.getElementById('action2sound').style.opacity = "1";
                          }

                          friendly_stop()
                      </script>
                  </td>
                  <td valign="top" width="65%">
                      <p><a href="">
                          <img src="images/new.png" alt="[NEW]" width="5%" style="border-style: none">
                          <heading>Action2Sound: Ambient-Aware Generation of
                              Action Sounds from Egocentric Videos</heading>
                      </a><br><strong>Changan Chen*</strong>, Puyuan Peng*, Ami Baid, Sherry Xue, Wei-Ning Hsu, David Harwath, Kristen Grauman<br>
                          <em>ECCV 2024 <span style="color:red;">(<b>Oral</b>)</span><br></em>
                          <a href="https://arxiv.org/abs/2406.09272">paper | </a>
                          <a href="https://vision.cs.utexas.edu/projects/action2sound">project | </a>
                          <a href="https://ego4dsounds.github.io">data | </a>
                          <a href="https://github.com/ChanganVR/action2sound">code</a>
                  </p></td>
              </tr>
          </tbody></table>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                  <tbody><tr>
                      <td>
                          <heading>Invited Talks</heading>
                      </td>
                  </tr>
              </tbody></table>
              <table class="news-table" width="100%" align="center" border="0" style="text-align: justify">
                  <colgroup>
                      <col width="15%">
                      <col width="85%">
                  </colgroup>
                  <tbody>
                  <tr>
                      <td valign="top" align="center"><strong>Dec 2023</strong></td>
                      <td> Invited talk at <a href="https://steinhardt.nyu.edu/marl">NYU</a>, "4D Audio-Visual Perception: Simulating, Synthesizing and Navigating with Sounds in Spaces" (<a href="talks/marl.pdf">Slides</a>)
                      </td>
                  </tr>
                  </tbody>
              </table>
              <table align="center">
                  <tbody>
                  <tr>
                      <td width="16%" align="center">
                          <a href="https://www.zju.edu.cn/english/" target="_blank">
                              <img style="width:120px" src="images/zju.png"></a>&nbsp;
                      </td>
                      <td width="16%" align="center">
                          <a href="https://www.sfu.ca/" target="_blank">
                              <img style="width:120px" src="images/sfu.png"></a>&nbsp;
                      </td>
                      <td width="16%" align="center">
                          <a href="https://www.epfl.ch/en/" target="_blank">
                              <img style="width:120px" src="images/epfl.png"></a>&nbsp;
                      </td>
                      <td width="16%" align="center">
                          <a href="https://research.fb.com/category/facebook-ai-research" target="_blank">
                              <img style="width:120px" src="images/fair.png"></a>&nbsp;
                      </td>
                      <td width="16%" align="center">
                          <a href="https://www.utexas.edu/" target="_blank">
                              <img style="width:120px" src="images/ut.png"></a>&nbsp;
                      </td>
                      <td width="16%" align="center">
                          <a href="https://www.utexas.edu/" target="_blank">
                              <img style="width:120px" src="images/stanford.png"></a>&nbsp;
                      </td>
                  </tr>
                  <tr>
                      <td width="20%" align="center"><font size="2">ZJU, China<br>2014-2016</font></td>
                      <td width="20%" align="center"><font size="2">SFU, Canada<br>2016-2019</font></td>
                      <td width="20%" align="center"><font size="2">EPFL, Switzerland<br>2018</font></td>
                      <td width="20%" align="center"><font size="2">FAIR, USA &amp; UK<br>2020 - 2022</font></td>
                      <td width="20%" align="center"><font size="2">UT AUSTIN, USA<br>2019 - 2024</font></td>
                      <td width="20%" align="center"><font size="2">Stanford, USA<br>2024 - present</font></td>
                  </tr>
                  </tbody>
              </table>

          <!--<table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
          <!--<tr>-->
          <!--<td>-->
          <!--<br>-->
          <!--<p align="right"><font size="2">-->
          <!--<a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of flattery)</a>-->
          <!--</font>-->
          <!--</p>-->
          <!--</td>-->
          <!--</tr>-->
          <!--</table>-->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
              <tr>
                  <td><br>
                      <p align="right"><font size="2">
                          Template credits: <a href="https://unnat.github.io/">Unnat</a>, <a href="https://jonbarron.info/">Jon</a>
                      </font></p></td>
              </tr>
              </tbody>
          </table>

      </td>
  </tr>
</tbody></table>


<div id="sff-extension" data-sff-extension-version="0.6.0.0"></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>